transformers == 4.32.0
accelerate >= 0.20.1
datasets
evaluate
scikit-learn
deepspeed

sentencepiece

packaging
git+https://github.com/Dao-AILab/flash-attention#subdirectory=csrc/layer_norm
flash-attn >= 2.2.3